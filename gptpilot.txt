─────────────────────────────
Fichier : core/agents/async_operations.py
─────────────────────────────

import logging
from typing import Optional, List, Dict
from dataclasses import dataclass

log = logging.getLogger(__name__)

@dataclass
class UserInput:
    button: Optional[str] = None
    text: Optional[str] = None
    cancelled: bool = False

class AsyncOperations:
    
    async def send_key_expired(self, message: Optional[str] = None):
        """
        Notifie que la clé a expiré.
        """
        log.warning(f"Key expired: {message or 'No details provided'}")

    async def send_app_finished(self, app_id: Optional[str] = None, app_name: Optional[str] = None, folder_name: Optional[str] = None):
        """
        Notification quand une application est terminée.
        """
        log.info(f"App Finished: {app_name} (ID: {app_id}) in {folder_name}")

    async def send_feature_finished(self, app_id: Optional[str] = None, app_name: Optional[str] = None, folder_name: Optional[str] = None):
        """
        Notification quand une fonctionnalité est terminée.
        """
        log.info(f"Feature finished in {app_name} (ID: {app_id}) stored in {folder_name}")

    async def ask_question(
        self,
        question: str,
        *,
        buttons: Optional[Dict[str, str]] = None,
        default: Optional[str] = None,
        buttons_only: bool = False,
        allow_empty: bool = False,
        full_screen: Optional[bool] = False,
        hint: Optional[str] = None,
        verbose: bool = True,
        initial_text: Optional[str] = None,
        source: Optional[str] = None,
        project_state_id: Optional[str] = None,
        extra_info: Optional[str] = None,
        placeholder: Optional[str] = None
    ) -> UserInput:
        """
        Pose une question à l'utilisateur et retourne la réponse.
        """
        log.debug(f"Asking question: {question}")
        if buttons:
            log.debug(f"Options: {buttons}")
        # Ici, on simule la réponse utilisateur.
        return UserInput(button=default or "OK", text=None)

    async def send_project_stage(self, data: dict):
        """
        Envoie une mise à jour de l'état du projet.
        """
        log.info(f"Project Stage Update: {data}")

    async def send_task_progress(self, index: int, n_tasks: int, description: str, source: str, status: str):
        """
        Mise à jour de l'avancement d'une tâche.
        """
        log.info(f"Task {index}/{n_tasks}: {description} - Status: {status}")

    async def send_step_progress(self, index: int, n_steps: int, step: dict, task_source: str):
        """
        Mise à jour de l'avancement d'une étape.
        """
        log.info(f"Step {index}/{n_steps}: {step.get('description', 'N/A')} in {task_source}")

    async def send_modified_files(self, modified_files: Dict[str, str]):
        """
        Envoie la liste des fichiers modifiés.
        """
        log.info(f"Modified files: {modified_files}")

    async def send_run_command(self, run_command: str):
        """
        Exécute une commande et journalise.
        """
        log.info(f"Executing command: {run_command}")

    async def send_project_root(self, path: str):
        """
        Définit le répertoire racine du projet.
        """
        log.info(f"Project root set to: {path}")

    async def start_important_stream(self):
        """
        Démarre un flux important.
        """
        log.info("Starting important stream...")

    async def send_project_stats(self, stats: dict):
        """
        Envoie les statistiques du projet.
        """
        log.info(f"Project Stats: {stats}")

    async def send_file_status(self, file_path: str, file_status: str):
        """
        Met à jour l'état d'un fichier.
        """
        log.info(f"File '{file_path}' status updated to {file_status}")

    async def send_bug_hunter_status(self, status: str, num_cycles: int):
        """
        Met à jour le statut du Bug Hunter.
        """
        log.info(f"Bug Hunter Status: {status}, Cycles: {num_cycles}")

─────────────────────────────
Fichier : core/agents/architect.py
─────────────────────────────

import json
from enum import Enum
from typing import Any, Optional

from pydantic import BaseModel, Field

from core.agents.base import BaseAgent
from core.agents.convo import AgentConvo
from core.agents.response import AgentResponse
from core.db.models import Specification
from core.llm.parser import JSONParser
from core.log import get_logger
from core.telemetry import telemetry
from core.templates.base import BaseProjectTemplate, NoOptions
from core.templates.example_project import EXAMPLE_PROJECTS
from core.templates.registry import (
    PROJECT_TEMPLATES,
    ProjectTemplateEnum,
)

ARCHITECTURE_STEP_NAME = "Project architecture"
WARN_SYSTEM_DEPS = ["docker", "kubernetes", "microservices"]
WARN_FRAMEWORKS = ["next.js", "vue", "vue.js", "svelte", "angular"]
WARN_FRAMEWORKS_URL = "https://github.com/Pythagora-io/gpt-pilot/wiki/Using-GPT-Pilot-with-frontend-frameworks"

log = get_logger(__name__)

class AppType(str, Enum):
    WEB = "web-app"
    API = "api-service"
    MOBILE = "mobile-app"
    DESKTOP = "desktop-app"
    CLI = "cli-tool"

class SystemDependency(BaseModel):
    name: str = Field(
        None,
        description="Name of the system dependency, for example Node.js or Python.",
    )
    description: str = Field(
        None,
        description="One-line description of the dependency.",
    )
    test: str = Field(
        None,
        description="Command line to test whether the dependency is available on the system.",
    )
    required_locally: bool = Field(
        None,
        description="Whether this dependency must be installed locally (as opposed to connecting to cloud or other server)",
    )

class PackageDependency(BaseModel):
    name: str = Field(
        None,
        description="Name of the package dependency, for example Express or React.",
    )
    description: str = Field(
        None,
        description="One-line description of the dependency.",
    )

class Architecture(BaseModel):
    app_type: AppType = Field(
        AppType.WEB,
        description="Type of the app to build.",
    )
    system_dependencies: list[SystemDependency] = Field(
        None,
        description="List of system dependencies required to build and run the app.",
    )
    package_dependencies: list[PackageDependency] = Field(
        None,
        description="List of framework/language-specific packages used by the app.",
    )

class TemplateSelection(BaseModel):
    architecture: str = Field(
        None,
        description="General description of the app architecture.",
    )
    template: Optional[ProjectTemplateEnum] = Field(
        None,
        description="Project template to use for the app, or null if no template is a good fit.",
    )

class Architect(BaseAgent):
    agent_type = "architect"
    display_name = "Architect"

    async def run(self) -> AgentResponse:
        spec = self.current_state.specification.clone()

        if spec.example_project:
            self.prepare_example_project(spec)
        else:
            await self.plan_architecture(spec)

        await self.check_system_dependencies(spec)

        self.next_state.specification = spec
        telemetry.set("templates", spec.templates)
        self.next_state.action = ARCHITECTURE_STEP_NAME
        return AgentResponse.done(self)

    async def select_templates(self, spec: Specification) -> tuple[str, dict[ProjectTemplateEnum, Any]]:
        await self.send_message("Selecting starter templates ...")
        llm = self.get_llm()
        convo = (
            AgentConvo(self)
            .template("select_templates", templates=PROJECT_TEMPLATES)
            .require_schema(TemplateSelection)
        )
        tpl: TemplateSelection = await llm(convo, parser=JSONParser(TemplateSelection))
        templates = {}
        # Template selection logic commented out – à activer si nécessaire
        return tpl.architecture, templates

    async def plan_architecture(self, spec: Specification):
        await self.send_message("Planning project architecture ...")
        architecture_description, templates = await self.select_templates(spec)
        await self.send_message("Picking technologies to use ...")
        llm = self.get_llm(stream_output=True)
        convo = (
            AgentConvo(self)
            .template("technologies", templates=templates, architecture=architecture_description)
            .require_schema(Architecture)
        )
        arch: Architecture = await llm(convo, parser=JSONParser(Architecture))
        await self.check_compatibility(arch)
        spec.architecture = architecture_description
        spec.templates = {t.name: t.options_dict for t in templates.values()}
        spec.system_dependencies = [d.model_dump() for d in arch.system_dependencies]
        spec.package_dependencies = [d.model_dump() for d in arch.package_dependencies]
        telemetry.set("architecture", json.loads(arch.model_dump_json()))

    async def check_compatibility(self, arch: Architecture) -> bool:
        warn_system_deps = [dep.name for dep in arch.system_dependencies if dep.name.lower() in WARN_SYSTEM_DEPS]
        warn_package_deps = [dep.name for dep in arch.package_dependencies if dep.name.lower() in WARN_FRAMEWORKS]

        if warn_system_deps:
            await self.ask_question(
                f"Warning: Pythagora doesn't officially support {', '.join(warn_system_deps)}. You can try to use {'it' if len(warn_system_deps) == 1 else 'them'}, but you may run into problems.",
                buttons={"continue": "Continue"},
                buttons_only=True,
                default="continue",
            )

        if warn_package_deps:
            await self.ask_question(
                f"Warning: Pythagora works best with vanilla JavaScript. You can try to use {', '.join(warn_package_deps)}, but you may run into problems. Visit {WARN_FRAMEWORKS_URL} for more information.",
                buttons={"continue": "Continue"},
                buttons_only=True,
                default="continue",
            )
        return True

    def prepare_example_project(self, spec: Specification):
        log.debug(f"Setting architecture for example project: {spec.example_project}")
        arch = EXAMPLE_PROJECTS[spec.example_project]["architecture"]
        spec.architecture = arch["architecture"]
        spec.system_dependencies = arch["system_dependencies"]
        spec.package_dependencies = arch["package_dependencies"]
        spec.templates = arch["templates"]
        telemetry.set("templates", spec.templates)

    async def check_system_dependencies(self, spec: Specification):
        deps = spec.system_dependencies
        for dep in deps:
            await self.send_message(f"Checking if {dep['name']} is available ...")
            status_code, _, _ = await self.process_manager.run_command(dep["test"])
            dep["installed"] = bool(status_code == 0)
            if status_code != 0:
                remedy = "Please install it before proceeding with your app." if dep["required_locally"] else "If you would like to use it locally, please install it before proceeding."
                await self.send_message(f"❌ {dep['name']} is not available. {remedy}")
                await self.ask_question(
                    "",
                    buttons={"continue": f"I've installed {dep['name']}"},
                    buttons_only=True,
                    default="continue",
                )
            else:
                await self.send_message(f"✅ {dep['name']} is available.")

    async def configure_template(self, spec: Specification, template_class: BaseProjectTemplate) -> BaseModel:
        if template_class.options_class is NoOptions:
            return NoOptions()
        llm = self.get_llm(stream_output=True)
        convo = (
            AgentConvo(self)
            .template("configure_template", project_description=spec.description, project_template=template_class)
            .require_schema(template_class.options_class)
        )
        return await llm(convo, parser=JSONParser(template_class.options_class))

─────────────────────────────
Fichier : core/agents/developer.py
─────────────────────────────

from core.agents.base import BaseAgent
from core.agents.response import AgentResponse
from core.agents.convo import AgentConvo
from core.llm.parser import JSONParser
from pydantic import BaseModel

# Exemple de schéma pour la décomposition de tâche
class SomeTaskSchema(BaseModel):
    steps: list[str]

class Developer(BaseAgent):
    agent_type = "developer"
    display_name = "Developer"

    async def run(self) -> AgentResponse:
        await self.send_message("Analyzing task instructions ...")
        llm = self.get_llm()
        convo = AgentConvo(self).template("parse_task", task=self.current_state.current_task)
        parsed_task = await llm(convo, parser=JSONParser(SomeTaskSchema))
        if not parsed_task or not getattr(parsed_task, "steps", None):
            await self.send_message("Task analysis failed, please provide more details.")
            return AgentResponse.revise_spec(self)
        filtered_files = await self.filter_files(parsed_task)
        await self.send_message(f"Identified {len(filtered_files)} file(s) to update.")
        for file in filtered_files:
            await self.implement_file_changes(file, parsed_task)
        self.next_state.complete_step("developer_task")
        return AgentResponse.done(self)
    
    async def filter_files(self, task):
        return [f for f in self.current_state.files if "target" in f.path]
    
    async def implement_file_changes(self, file, task):
        await self.send_message(f"Implementing changes in {file.path}")

─────────────────────────────
Fichier : core/agents/bug_hunter.py
─────────────────────────────

import json
from enum import Enum

from pydantic import BaseModel, Field

from core.agents.base import BaseAgent
from core.agents.convo import AgentConvo
from core.agents.mixins import ChatWithBreakdownMixin, TestSteps
from core.agents.response import AgentResponse
from core.config import CHECK_LOGS_AGENT_NAME, magic_words
from core.db.models.project_state import IterationStatus
from core.llm.parser import JSONParser
from core.log import get_logger
from core.telemetry import telemetry
from core.ui.base import ProjectStage, pythagora_source

log = get_logger(__name__)

class HuntConclusionType(str, Enum):
    ADD_LOGS = magic_words.ADD_LOGS
    PROBLEM_IDENTIFIED = magic_words.PROBLEM_IDENTIFIED

class HuntConclusionOptions(BaseModel):
    conclusion: HuntConclusionType = Field(
        description=f"If more logs are needed to identify the problem, respond with '{magic_words.ADD_LOGS}'. If the problem is identified, respond with '{magic_words.PROBLEM_IDENTIFIED}'."
    )

class ImportantLog(BaseModel):
    logCode: str = Field(description="Actual line of code that prints the log.")
    shouldBeDifferent: bool = Field(
        description="Whether the current output should be different from the expected output."
    )
    filePath: str = Field(description="Path to the file in which the log exists.")
    currentOutput: str = Field(description="Current output of the log.")
    expectedOutput: str = Field(description="Expected output of the log.")
    explanation: str = Field(description="A brief explanation of the log.")

class ImportantLogsForDebugging(BaseModel):
    logs: list[ImportantLog] = Field(description="Important logs that will help the human debug the current bug.")

class BugHunter(ChatWithBreakdownMixin, BaseAgent):
    agent_type = "bug-hunter"
    display_name = "Bug Hunter"

    async def run(self) -> AgentResponse:
        current_iteration = self.current_state.current_iteration
        if "bug_reproduction_description" not in current_iteration:
            await self.get_bug_reproduction_instructions()
        if current_iteration["status"] == IterationStatus.HUNTING_FOR_BUG:
            return await self.check_logs()
        elif current_iteration["status"] == IterationStatus.AWAITING_USER_TEST:
            await self.ui.send_bug_hunter_status("close_status", 0)
            return await self.ask_user_to_test(False, True)
        elif current_iteration["status"] == IterationStatus.AWAITING_BUG_REPRODUCTION:
            await self.ui.send_bug_hunter_status("close_status", 0)
            return await self.ask_user_to_test(True, False)
        elif current_iteration["status"] == IterationStatus.START_PAIR_PROGRAMMING:
            await self.ui.send_bug_hunter_status("close_status", 0)
            return await self.start_pair_programming()

    async def get_bug_reproduction_instructions(self):
        await self.send_message("Finding a way to reproduce the bug ...")
        llm = self.get_llm()
        convo = (
            AgentConvo(self)
            .template("get_bug_reproduction_instructions",
                      current_task=self.current_state.current_task,
                      user_feedback=self.current_state.current_iteration["user_feedback"],
                      user_feedback_qa=self.current_state.current_iteration["user_feedback_qa"],
                      docs=self.current_state.docs,
                      next_solution_to_try=None)
            .require_schema(TestSteps)
        )
        bug_reproduction_instructions: TestSteps = await llm(convo, parser=JSONParser(TestSteps), temperature=0)
        self.next_state.current_iteration["bug_reproduction_description"] = json.dumps(
            [test.dict() for test in bug_reproduction_instructions.steps]
        )

    async def check_logs(self, logs_message: str = None):
        llm = self.get_llm(CHECK_LOGS_AGENT_NAME, stream_output=True)
        convo = self.generate_iteration_convo_so_far()
        await self.ui.start_breakdown_stream()
        human_readable_instructions = await llm(convo, temperature=0.5)
        convo.assistant(human_readable_instructions)
        human_readable_instructions = await self.chat_with_breakdown(convo, human_readable_instructions)
        convo = (
            AgentConvo(self)
            .template("bug_found_or_add_logs", hunt_conclusion=human_readable_instructions)
            .require_schema(HuntConclusionOptions)
        )
        llm = self.get_llm()
        hunt_conclusion = await llm(convo, parser=JSONParser(HuntConclusionOptions), temperature=0)
        bug_hunting_cycles = self.current_state.current_iteration.get("bug_hunting_cycles")
        num_bug_hunting_cycles = len(bug_hunting_cycles) if bug_hunting_cycles else 0
        if hunt_conclusion.conclusion == magic_words.PROBLEM_IDENTIFIED:
            self.set_data_for_next_hunting_cycle(human_readable_instructions, IterationStatus.AWAITING_BUG_FIX)
            await self.send_message("Found the bug. I'm attempting to fix it ...")
            await self.ui.send_bug_hunter_status("fixing_bug", num_bug_hunting_cycles)
        else:
            self.set_data_for_next_hunting_cycle(human_readable_instructions, IterationStatus.AWAITING_LOGGING)
            await self.send_message("Adding more logs to identify the bug ...")
            await self.ui.send_bug_hunter_status("adding_logs", num_bug_hunting_cycles)
        self.next_state.flag_iterations_as_modified()
        return AgentResponse.done(self)

    async def ask_user_to_test(self, awaiting_bug_reproduction: bool = False, awaiting_user_test: bool = False):
        await self.ui.stop_app()
        test_instructions = self.current_state.current_iteration["bug_reproduction_description"]
        await self.ui.send_message("Start the app and test it by following these instructions:\n\n", source=pythagora_source)
        await self.send_message("")
        await self.ui.send_test_instructions(test_instructions, project_state_id=str(self.current_state.id))
        if self.current_state.run_command:
            await self.ui.send_run_command(self.current_state.run_command)
        await self.ask_question(
            "Please test the app again.",
            buttons={"done": "I am done testing"},
            buttons_only=True,
            default="continue",
            extra_info="restart_app",
            hint="Instructions for testing:\n\n" + self.current_state.current_iteration["bug_reproduction_description"],
        )
        if awaiting_user_test:
            buttons = {"yes": "Yes, the issue is fixed", "no": "No", "start_pair_programming": "Start Pair Programming"}
            user_feedback = await self.ask_question(
                "Is the bug you reported fixed now?",
                buttons=buttons,
                default="yes",
                buttons_only=True,
                hint="Instructions for testing:\n\n" + self.current_state.current_iteration["bug_reproduction_description"],
            )
            self.next_state.current_iteration["bug_hunting_cycles"][-1]["fix_attempted"] = True
            if user_feedback.button == "yes":
                self.next_state.complete_iteration()
            elif user_feedback.button == "start_pair_programming":
                self.next_state.current_iteration["status"] = IterationStatus.START_PAIR_PROGRAMMING
                self.next_state.flag_iterations_as_modified()
            else:
                awaiting_bug_reproduction = True
        if awaiting_bug_reproduction:
            buttons = {
                "done": "Bug is fixed",
                "continue": "Continue without feedback",
                "start_pair_programming": "Start Pair Programming",
            }
            await self.ui.send_project_stage({"stage": ProjectStage.ADDITIONAL_FEEDBACK})
            user_feedback = await self.ask_question(
                "Please add any additional feedback that could help Pythagora solve this bug",
                buttons=buttons,
                default="continue",
                extra_info="collect_logs",
                hint="Instructions for testing:\n\n" + self.current_state.current_iteration["bug_reproduction_description"],
            )
            if user_feedback.button == "done":
                self.next_state.complete_iteration()
                return AgentResponse.done(self)
            elif user_feedback.button == "start_pair_programming":
                self.next_state.current_iteration["status"] = IterationStatus.START_PAIR_PROGRAMMING
                self.next_state.flag_iterations_as_modified()
                return AgentResponse.done(self)
            self.next_state.current_iteration["bug_hunting_cycles"][-1]["backend_logs"] = None
            self.next_state.current_iteration["bug_hunting_cycles"][-1]["frontend_logs"] = None
            self.next_state.current_iteration["bug_hunting_cycles"][-1]["user_feedback"] = user_feedback.text
            self.next_state.current_iteration["status"] = IterationStatus.HUNTING_FOR_BUG
        return AgentResponse.done(self)

    async def start_pair_programming(self):
        llm = self.get_llm(stream_output=True)
        convo = self.generate_iteration_convo_so_far(True)
        if len(convo.messages) > 1:
            convo.remove_last_x_messages(1)
        convo = convo.template("problem_explanation")
        await self.ui.start_important_stream()
        initial_explanation = await llm(convo, temperature=0.5)
        llm = self.get_llm()
        convo = convo.template("data_about_logs").require_schema(ImportantLogsForDebugging)
        data_about_logs = await llm(convo, parser=JSONParser(ImportantLogsForDebugging), temperature=0.5)
        await self.ui.send_data_about_logs(
            {
                "logs": [
                    {
                        "currentLog": d.currentOutput,
                        "expectedLog": d.expectedOutput,
                        "explanation": d.explanation,
                        "filePath": d.filePath,
                        "logCode": d.logCode,
                        "shouldBeDifferent": d.shouldBeDifferent,
                    }
                    for d in data_about_logs.logs
                ]
            }
        )
        while True:
            self.next_state.current_iteration["initial_explanation"] = initial_explanation
            next_step = await self.ask_question(
                "What do you want to do?",
                buttons={
                    "question": "I have a question",
                    "done": "I fixed the bug myself",
                    "tell_me_more": "Tell me more about the bug",
                    "solution_hint": "I think I know where the problem is",
                    "other": "Other",
                },
                buttons_only=True,
                default="continue",
                hint="Instructions for testing:\n\n" + self.current_state.current_iteration["bug_reproduction_description"],
            )
            await telemetry.trace_code_event(
                "pair-programming",
                {
                    "button": next_step.button,
                    "num_tasks": len(self.current_state.tasks),
                    "num_epics": len(self.current_state.epics),
                    "num_iterations": len(self.current_state.iterations),
                    "app_id": str(self.state_manager.project.id),
                    "app_name": self.state_manager.project.name,
                    "folder_name": self.state_manager.project.folder_name,
                },
            )
            convo.remove_last_x_messages(2)
            if len(convo.messages) > 10:
                convo.trim(1, 2)
            if next_step.button == "done":
                self.next_state.complete_iteration()
                break
            elif next_step.button == "question":
                user_response = await self.ask_question("Oh, cool, what would you like to know?")
                convo = convo.template("ask_a_question", question=user_response.text)
                await self.ui.start_important_stream()
                llm_answer = await llm(convo, temperature=0.5)
                await self.send_message(llm_answer)
            elif next_step.button == "tell_me_more":
                convo.template("tell_me_more")
                await self.ui.start_important_stream()
                response = await llm(convo, temperature=0.5)
                await self.send_message(response)
            elif next_step.button == "other":
                user_response = await self.ask_question("Let me know what you think ...")
                convo = convo.template("ask_a_question", question=user_response.text)
                await self.ui.start_important_stream()
                llm_answer = await llm(convo, temperature=0.5)
                await self.send_message(llm_answer)
            elif next_step.button == "solution_hint":
                human_hint_label = "Amazing! How do you think we can solve this bug?"
                while True:
                    human_hint = await self.ask_question(human_hint_label)
                    convo = convo.template("instructions_from_human_hint", human_hint=human_hint.text)
                    await self.ui.start_important_stream()
                    llm = self.get_llm(CHECK_LOGS_AGENT_NAME, stream_output=True)
                    human_readable_instructions = await llm(convo, temperature=0.5)
                    human_approval = await self.ask_question(
                        "Can I implement this solution?", buttons={"yes": "Yes", "no": "No"}, buttons_only=True
                    )
                    llm = self.get_llm(stream_output=True)
                    if human_approval.button == "yes":
                        self.set_data_for_next_hunting_cycle(human_readable_instructions, IterationStatus.AWAITING_BUG_FIX)
                        self.next_state.flag_iterations_as_modified()
                        break
                    else:
                        human_hint_label = "Oh, my bad, what did I misunderstand?"
                break
            elif next_step.button == "tell_me_more":
                convo.template("tell_me_more")
                await self.ui.start_important_stream()
                response = await llm(convo, temperature=0.5)
                await self.send_message(response)
                continue
        return AgentResponse.done(self)

    def generate_iteration_convo_so_far(self, omit_last_cycle=False):
        convo = AgentConvo(self).template(
            "iteration",
            current_task=self.current_state.current_task,
            user_feedback=self.current_state.current_iteration["user_feedback"],
            user_feedback_qa=self.current_state.current_iteration["user_feedback_qa"],
            docs=self.current_state.docs,
            magic_words=magic_words,
            next_solution_to_try=None,
            test_instructions=json.loads(self.current_state.current_task.get("test_instructions") or "[]"),
        )
        hunting_cycles = self.current_state.current_iteration.get("bug_hunting_cycles", [])[
            0 : (-1 if omit_last_cycle else None)
        ]
        for hunting_cycle in hunting_cycles:
            convo = convo.assistant(hunting_cycle["human_readable_instructions"]).template(
                "log_data",
                backend_logs=hunting_cycle.get("backend_logs"),
                frontend_logs=hunting_cycle.get("frontend_logs"),
                fix_attempted=hunting_cycle.get("fix_attempted"),
                user_feedback=hunting_cycle.get("user_feedback"),
            )
        return convo

    def set_data_for_next_hunting_cycle(self, human_readable_instructions, new_status):
        self.next_state.current_iteration["description"] = human_readable_instructions
        self.next_state.current_iteration["bug_hunting_cycles"] += [
            {
                "human_readable_instructions": human_readable_instructions,
                "fix_attempted": any(
                    c["fix_attempted"] for c in self.current_state.current_iteration["bug_hunting_cycles"]
                ),
            }
        ]
        self.next_state.current_iteration["status"] = new_status

    async def continue_on(self, convo, button_value, user_response):
        llm = self.get_llm(stream_output=True)
        convo = convo.template("continue_on")
        continue_on = await llm(convo, temperature=0.5)
        return continue_on

─────────────────────────────
Fichier : core/config/magic_words.py
─────────────────────────────

from dataclasses import dataclass

@dataclass(frozen=True)
class MagicWords:
    ADD_LOGS: str = "ADD_LOGS"
    PROBLEM_IDENTIFIED: str = "PROBLEM_IDENTIFIED"
    # D'autres magic words peuvent être ajoutés ici

magic_words = MagicWords()

─────────────────────────────
Fichier : core/config/user_settings.py
─────────────────────────────

from pydantic import BaseModel, Field, ValidationError
import os
import json

class UserSettings(BaseModel):
    theme: str = Field("light", description="Theme de l'interface: 'light' ou 'dark'")
    language: str = Field("fr", description="Langue de l'interface")
    notifications_enabled: bool = Field(True, description="Activation des notifications")

def load_user_settings(settings_file: str = "user_settings.json") -> UserSettings:
    try:
        if os.path.exists(settings_file):
            with open(settings_file, "r", encoding="utf-8") as f:
                data = json.load(f)
            return UserSettings(**data)
        else:
            return UserSettings()
    except (json.JSONDecodeError, ValidationError) as e:
        raise ValueError(f"Invalid user settings: {e}")

─────────────────────────────
Fichier : core/config/version.py
─────────────────────────────

def get_version() -> str:
    try:
        with open("VERSION", "r", encoding="utf-8") as f:
            version = f.read().strip()
        return version
    except Exception:
        return "unknown"

─────────────────────────────
Fichier : core/db/models/base.py
─────────────────────────────

from pydantic import BaseModel

class StrictBaseModel(BaseModel):
    class Config:
        extra = "forbid"  # Interdit les champs non définis
        orm_mode = True

─────────────────────────────
Fichier : core/db/session.py
─────────────────────────────

import os
import json
import asyncio
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker

DATABASE_URL = os.getenv("DATABASE_URL", "postgresql+asyncpg://postgres:postgres@localhost:5432/test")

engine = create_async_engine(DATABASE_URL, echo=True)
AsyncSessionLocal = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)

async def get_db_session():
    async with AsyncSessionLocal() as session:
        try:
            yield session
            await session.commit()
        except Exception as e:
            await session.rollback()
            raise e

─────────────────────────────
Fichier : core/db/setup.py
─────────────────────────────

import asyncio
from core.db.session import engine
from core.db.models import Base  # Tous vos modèles doivent hériter de Base

async def init_db():
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    print("Database initialized.")

if __name__ == "__main__":
    asyncio.run(init_db())

─────────────────────────────
Fichier : core/telemetry/telemetry.py
─────────────────────────────

import httpx
import logging

logger = logging.getLogger(__name__)

class Telemetry:
    def __init__(self, endpoint: str):
        self.endpoint = endpoint

    async def trace_event(self, event_name: str, data: dict):
        payload = {"event": event_name, "data": data}
        try:
            async with httpx.AsyncClient(timeout=5) as client:
                response = await client.post(self.endpoint, json=payload)
                response.raise_for_status()
                logger.info(f"Telemetry event '{event_name}' sent successfully.")
        except Exception as e:
            logger.error(f"Failed to send telemetry event '{event_name}': {e}")

telemetry = Telemetry("https://telemetry.example.com/trace")

─────────────────────────────
Fichier : core/disk/vfs.py
─────────────────────────────

import os
import fnmatch
import logging

logger = logging.getLogger(__name__)

class VirtualFileSystem:
    def __init__(self, root: str, ignore_patterns: list = None):
        self.root = root
        self.ignore_patterns = ignore_patterns or ['*.pyc', '__pycache__', '.git']

    def list_files(self) -> list:
        files_list = []
        for root, dirs, files in os.walk(self.root):
            dirs[:] = [d for d in dirs if not any(fnmatch.fnmatch(d, pattern) for pattern in self.ignore_patterns)]
            for file in files:
                if not any(fnmatch.fnmatch(file, pattern) for pattern in self.ignore_patterns):
                    files_list.append(os.path.join(root, file))
        logger.debug(f"Listed {len(files_list)} files from {self.root}")
        return files_list

    def read_file(self, file_path: str) -> str:
        full_path = os.path.join(self.root, file_path)
        with open(full_path, 'r', encoding='utf-8') as f:
            content = f.read()
        logger.debug(f"Read file: {full_path}")
        return content

    def write_file(self, file_path: str, content: str):
        full_path = os.path.join(self.root, file_path)
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(content)
        logger.info(f"Wrote file: {full_path}")

─────────────────────────────
Fichier : core/llm/base.py
─────────────────────────────

from abc import ABC, abstractmethod

class BaseLLMClient(ABC):
    def __init__(self, config, stream_handler=None, error_handler=None):
        self.config = config
        self.stream_handler = stream_handler
        self.error_handler = error_handler

    @abstractmethod
    async def __call__(self, convo, **kwargs):
        pass

    @classmethod
    def for_provider(cls, provider: str):
        if provider.lower() == "openai":
            from core.llm.openai_client import OpenAIClient
            return OpenAIClient
        raise ValueError(f"Unsupported provider: {provider}")

─────────────────────────────
Fichier : core/llm/parser.py
─────────────────────────────

import json

class JSONParser:
    def __init__(self, schema):
        self.schema = schema

    def __call__(self, text: str):
        try:
            data = json.loads(text)
            return self.schema(**data)
        except Exception as e:
            raise ValueError(f"Failed to parse JSON: {e}")

─────────────────────────────
Fichier : core/llm/prompt.py
─────────────────────────────

def format_prompt(template: str, context: dict) -> str:
    try:
        prompt = template.format(**context)
    except KeyError as e:
        raise ValueError(f"Missing placeholder in context: {e}")
    return prompt

─────────────────────────────
Fichier : core/llm/request_log.py
─────────────────────────────

import logging

logger = logging.getLogger(__name__)

def log_request(request_data: dict, response_data: dict):
    logger.info("LLM Request Log", extra={"request": request_data, "response": response_data})

─────────────────────────────
Fichier : core/ui/base.py
─────────────────────────────

import abc

class UIBase(abc.ABC):
    @abc.abstractmethod
    async def send_message(self, message: str, source: str = None, project_state_id: str = None):
        pass

    @abc.abstractmethod
    async def ask_question(self, question: str, **kwargs):
        pass

    @abc.abstractmethod
    async def send_stream_chunk(self, chunk: str, source: str = None, project_state_id: str = None):
        pass

─────────────────────────────
Fichier : core/ui/console.py
─────────────────────────────

import asyncio
import sys
from core.ui.base import UIBase

class ConsoleUI(UIBase):
    async def send_message(self, message: str, source: str = None, project_state_id: str = None):
        print(message)

    async def ask_question(self, question: str, **kwargs):
        print(question, end=' ', flush=True)
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(None, sys.stdin.readline)
        return response.strip()

    async def send_stream_chunk(self, chunk: str, source: str = None, project_state_id: str = None):
        print(chunk, end='', flush=True)

─────────────────────────────
Fichier : core/ui/ipc_client.py
─────────────────────────────

import asyncio
import websockets
import logging

logger = logging.getLogger(__name__)

class IPCClient:
    def __init__(self, uri: str):
        self.uri = uri
        self.connection = None
        self.lock = asyncio.Lock()

    async def connect(self):
        try:
            self.connection = await websockets.connect(self.uri)
            logger.info(f"Connected to IPC server at {self.uri}")
        except Exception as e:
            logger.error(f"Failed to connect to IPC server: {e}")
            raise

    async def send_message(self, message: str):
        async with self.lock:
            if self.connection is None:
                await self.connect()
            try:
                await self.connection.send(message)
                logger.debug(f"Sent message: {message}")
            except Exception as e:
                logger.error(f"Error sending message: {e}")
                await self.connect()
                await self.connection.send(message)

    async def receive_message(self) -> str:
        async with self.lock:
            if self.connection is None:
                await self.connect()
            try:
                message = await self.connection.recv()
                logger.debug(f"Received message: {message}")
                return message
            except Exception as e:
                logger.error(f"Error receiving message: {e}")
                raise

    async def close(self):
        if self.connection:
            await self.connection.close()
            logger.info("IPC connection closed")

─────────────────────────────
Fichier : core/ui/virtual.py
─────────────────────────────

import asyncio
import logging
from core.ui.base import UIBase

logger = logging.getLogger(__name__)

class VirtualUI(UIBase):
    def __init__(self):
        self.messages = []
        self.input_queue = asyncio.Queue()

    async def send_message(self, message: str, source: str = None, project_state_id: str = None):
        full_message = f"{source or 'VirtualUI'}: {message}"
        self.messages.append(full_message)
        logger.info(f"VirtualUI message: {full_message}")

    async def ask_question(self, question: str, **kwargs):
        await self.send_message(f"Question: {question}")
        answer = await self.input_queue.get()
        logger.info(f"VirtualUI received answer: {answer}")
        return answer

    async def send_stream_chunk(self, chunk: str, source: str = None, project_state_id: str = None):
        await self.send_message(f"Stream chunk: {chunk}", source, project_state_id)

    async def simulate_user_input(self, response: str):
        await self.input_queue.put(response)

─────────────────────────────
Fichier : core/cli/helpers.py
─────────────────────────────

import logging
import sys

def setup_logging():
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    handler = logging.StreamHandler(sys.stdout)
    formatter = logging.Formatter(fmt="%(asctime)s - %(name)s - %(levelname)s - %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
    handler.setFormatter(formatter)
    logger.addHandler(handler)

def print_header(header: str):
    print("=" * len(header))
    print(header)
    print("=" * len(header))

─────────────────────────────
Fichier : Dockerfile
─────────────────────────────

# Stage 1: Build
FROM python:3.12-slim as builder
WORKDIR /app
RUN apt-get update && apt-get install -y gcc build-essential && rm -rf /var/lib/apt/lists/*
COPY requirements.txt .
RUN pip install --upgrade pip && pip install --no-cache-dir -r requirements.txt
COPY . .
RUN python -m compileall .

# Stage 2: Runtime
FROM python:3.12-slim
WORKDIR /app
COPY --from=builder /app /app
ENV PYTHONUNBUFFERED=1
CMD ["python", "main.py"]

─────────────────────────────
Fichier : entrypoint.sh
─────────────────────────────

#!/bin/bash
set -e

: "${DATABASE_URL:?Variable DATABASE_URL non définie}"
: "${JWT_SECRET:?Variable JWT_SECRET non définie}"
: "${OPENAI_API_KEY:?Variable OPENAI_API_KEY non définie}"
echo "Starting the application..."
exec python main.py

─────────────────────────────
Fichier : .pre-commit-config.yaml
─────────────────────────────

repos:
  - repo: https://github.com/psf/black
    rev: 23.1.0
    hooks:
      - id: black
  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: end-of-file-fixer
      - id: trailing-whitespace

─────────────────────────────
Fichier : pyproject.toml
─────────────────────────────

[tool.black]
line-length = 88
target-version = ['py312']
include = '\.pyi?$'
exclude = '''
/(
    \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | _build
  | buck-out
  | build
  | dist
)/
'''

[tool.flake8]
max-line-length = 88
extend-ignore = ["E203", "W503"]

[tool.mypy]
python_version = 3.12
ignore_missing_imports = true

─────────────────────────────
Fichier : core/agents/external_docs.py
─────────────────────────────

import logging
from core.agents.base import BaseAgent
from core.agents.convo import AgentConvo
from core.llm.parser import JSONParser
from core.agents.response import AgentResponse

logger = logging.getLogger(__name__)

class ExternalDocs(BaseAgent):
    agent_type = "external-docs"
    display_name = "External Docs"

    async def run(self) -> AgentResponse:
        await self.send_message("Fetching external documentation...")
        llm = self.get_llm()
        convo = (
            AgentConvo(self)
            .template("create_docs_queries", query="Fetch documentation for current technologies")
            .require_schema(dict)
        )
        try:
            docs_response = await llm(convo, parser=JSONParser(dict))
            await self.send_message("External documentation fetched successfully.")
            self.next_state.external_docs = docs_response
            return AgentResponse.done(self)
        except Exception as e:
            logger.error(f"Error fetching external docs: {e}", exc_info=True)
            await self.send_message("Error fetching external documentation. Please try again later.")
            return AgentResponse.revise_spec(self)

─────────────────────────────
Fichier : core/agents/executor.py
─────────────────────────────

import asyncio
import logging
from core.agents.base import BaseAgent
from core.agents.response import AgentResponse

logger = logging.getLogger(__name__)

class Executor(BaseAgent):
    agent_type = "executor"
    display_name = "Executor"

    async def run(self) -> AgentResponse:
        command = self.current_state.run_command
        if not command:
            await self.send_message("No command to run.")
            return AgentResponse.done(self)
        status_code, stdout, stderr = await self.run_command_with_retries(command)
        await self.send_message(f"Command finished with code {status_code}")
        self.next_state.last_command_output = stdout
        return AgentResponse.done(self)

    async def run_command_with_retries(self, command: str, max_retries: int = 3, timeout: int = 10) -> tuple:
        for attempt in range(1, max_retries + 1):
            await self.send_message(f"Executing command (attempt {attempt}): {command}")
            code, out, err = await self.process_manager.run_command(command, timeout=timeout)
            logger.info(f"Attempt {attempt}: Exit code {code}")
            if code == 0:
                return code, out, err
            else:
                await asyncio.sleep(1)
        logger.error(f"Command '{command}' failed after {max_retries} attempts.")
        return code, out, err

─────────────────────────────
Fichier : core/agents/importer.py
─────────────────────────────

import logging
from core.agents.base import BaseAgent
from core.agents.response import AgentResponse
from core.agents.convo import AgentConvo
from core.llm.parser import JSONParser

logger = logging.getLogger(__name__)

class Importer(BaseAgent):
    agent_type = "importer"
    display_name = "Importer"

    async def run(self) -> AgentResponse:
        await self.send_message("Analyzing project structure...")
        llm = self.get_llm()
        convo = AgentConvo(self).template("analyze_project", files=self.current_state.files)
        analysis = await llm(convo, parser=JSONParser(dict))
        if not analysis or "entrypoints" not in analysis:
            await self.send_message("Project analysis incomplete. Please provide more information.")
            return AgentResponse.revise_spec(self)
        self.next_state.project_analysis = analysis
        await self.send_message("Project analysis completed successfully.")
        return AgentResponse.done(self)

─────────────────────────────
Fichier : core/agents/tech_lead.py
─────────────────────────────

import json
import logging
from core.agents.base import BaseAgent
from core.agents.response import AgentResponse
from core.agents.convo import AgentConvo
from core.llm.parser import JSONParser

logger = logging.getLogger(__name__)

from pydantic import BaseModel, Field

class RoadmapSchema(BaseModel):
    epics: list[dict] = Field(..., description="Liste des épics pour le projet")

class TechLead(BaseAgent):
    agent_type = "tech-lead"
    display_name = "Tech Lead"

    async def run(self) -> AgentResponse:
        await self.send_message("Planning project roadmap...")
        llm = self.get_llm()
        convo = AgentConvo(self).template("plan", project=self.current_state.project)
        roadmap = await llm(convo, parser=JSONParser(RoadmapSchema))
        if not roadmap or not getattr(roadmap, "epics", None):
            await self.send_message("Failed to generate a valid roadmap. Please revise the project specifications.")
            return AgentResponse.revise_spec(self)
        self.next_state.project.roadmap = roadmap.dict()
        await self.send_message("Project roadmap generated successfully.")
        return AgentResponse.done(self)

─────────────────────────────
Fichier : core/agents/tech_writer.py
─────────────────────────────

import logging
from core.agents.base import BaseAgent
from core.agents.response import AgentResponse
from core.agents.convo import AgentConvo
from core.llm.parser import OptionalCodeBlockParser

logger = logging.getLogger(__name__)

class TechWriter(BaseAgent):
    agent_type = "tech-writer"
    display_name = "Tech Writer"

    async def run(self) -> AgentResponse:
        await self.send_message("Generating project documentation...")
        llm = self.get_llm()
        convo = AgentConvo(self).template("create_readme", project=self.current_state.project)
        readme_content = await llm(convo, parser=OptionalCodeBlockParser())
        if not readme_content.strip():
            await self.send_message("Failed to generate documentation. Please check the project details.")
            return AgentResponse.revise_spec(self)
        await self.state_manager.save_file("README.md", readme_content)
        await self.send_message("Documentation generated and saved successfully.")
        return AgentResponse.done(self)

─────────────────────────────
Fichier : core/agents/problem_solver.py
─────────────────────────────

import logging
from core.agents.base import BaseAgent
from core.agents.response import AgentResponse
from core.agents.convo import AgentConvo
from core.llm.parser import JSONParser

logger = logging.getLogger(__name__)

class ProblemSolver(BaseAgent):
    agent_type = "problem-solver"
    display_name = "Problem Solver"

    async def run(self) -> AgentResponse:
        await self.send_message("Analyzing the problem description...")
        llm = self.get_llm()
        convo = AgentConvo(self).template("problem_analysis", problem=self.current_state.problem_description)
        analysis = await llm(convo, parser=JSONParser(dict))
        if not analysis:
            await self.send_message("Problem analysis failed. Please rephrase the issue.")
            return AgentResponse.revise_spec(self)
        solution = analysis.get("proposed_solution", "No solution proposed")
        await self.send_message(f"Proposed solution: {solution}")
        self.next_state.problem_solution = solution
        return AgentResponse.done(self)

─────────────────────────────
Fichier : core/agents/mixins.py
─────────────────────────────

import difflib

class FileDiffMixin:
    def get_diff(self, old_content: str, new_content: str) -> str:
        diff = difflib.unified_diff(
            old_content.splitlines(), new_content.splitlines(),
            fromfile='old', tofile='new', lineterm=''
        )
        return "\n".join(diff)

─────────────────────────────
Fichier : core/agents/response.py
─────────────────────────────

class AgentResponse:
    def __init__(self, response_type: str, data=None):
        self.type = response_type
        self.data = data

    @staticmethod
    def done(agent):
        return AgentResponse("done")

    @staticmethod
    def revise_spec(agent):
        return AgentResponse("revise_spec")

    @staticmethod
    def input_required(agent, fields):
        return AgentResponse("input_required", data=fields)

    def requires_revision(self) -> bool:
        return self.type == "revise_spec"

─────────────────────────────
Fichier : core/agents/troubleshooter.py
─────────────────────────────

import logging
from core.agents.base import BaseAgent
from core.agents.response import AgentResponse

logger = logging.getLogger(__name__)

class Troubleshooter(BaseAgent):
    agent_type = "troubleshooter"
    display_name = "Troubleshooter"

    async def run(self) -> AgentResponse:
        await self.send_message("Starting troubleshooting...")
        error = self.current_state.get("last_error")
        if not error:
            await self.send_message("No error found to troubleshoot.")
            return AgentResponse.done(self)
        convo = self.generate_troubleshooting_convo(error)
        llm = self.get_llm(stream_output=True)
        explanation = await llm(convo, temperature=0.5)
        await self.send_message(f"Troubleshooting explanation: {explanation}")
        self.next_state.error_fixed = True
        return AgentResponse.done(self)

    def generate_troubleshooting_convo(self, error: str):
        convo = self.generate_iteration_convo_so_far(omit_last_cycle=True)
        convo.user(f"Troubleshoot error: {error}")
        return convo

─────────────────────────────
Fichier : core/cli/main.py
─────────────────────────────

#!/usr/bin/env python
import argparse
import sys
import asyncio
from core.cli.helpers import setup_logging
from core.state.state_manager import StateManager
from core.agents.architect import Architect
from core.agents.developer import Developer
from core.agents.bug_hunter import BugHunter
from core.agents.response import AgentResponse

async def main():
    setup_logging()
    parser = argparse.ArgumentParser(description="GPT Pilot CLI")
    parser.add_argument("--spec", type=str, help="Path to the project specification file", required=False)
    parser.add_argument(
        "--action",
        type=str,
        choices=["architect", "develop", "test"],
        default="architect",
        help="Action to perform (default: architect)"
    )
    args = parser.parse_args()
    try:
        if args.spec:
            state_manager = StateManager.load(args.spec)
        else:
            state_manager = StateManager.create_default()
    except Exception as e:
        print(f"Failed to initialize project state: {e}")
        sys.exit(1)
    if args.action == "architect":
        agent = Architect(state_manager)
    elif args.action == "develop":
        agent = Developer(state_manager)
    elif args.action == "test":
        agent = BugHunter(state_manager)
    else:
        print("Invalid action.")
        sys.exit(1)
    try:
        response = await agent.run()
        if response.type == AgentResponse.INPUT_REQUIRED:
            print("Additional input required.")
        else:
            print("Action completed successfully.")
    except Exception as e:
        print(f"An error occurred during execution: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())

─────────────────────────────
Fichier : on-event-extension-install.sh
─────────────────────────────

#!/bin/bash
set -e

echo "Starting on-event extension installation..."

if [ -z "$REQUIRED_EXTENSION" ]; then
  echo "Required extension identifier is not set. Exiting."
  exit 1
fi

echo "Installing extension: $REQUIRED_EXTENSION"
# Placez ici vos commandes d'installation spécifiques

echo "Extension installed successfully."

─────────────────────────────
Fichier : config-docker.json
─────────────────────────────

{
  "build_args": {
    "PYTHON_VERSION": "3.12"
  },
  "docker": {
    "context": ".",
    "dockerfile": "Dockerfile"
  }
}

─────────────────────────────
Fichier : requirements.txt
─────────────────────────────

fastapi==0.95.2
uvicorn==0.22.0
openai==0.27.4
httpx==0.24.0
pydantic==1.10.7
SQLAlchemy==2.0.15
asyncpg==0.29.0
psycopg[binary]==3.2.10
websockets==10.3
